from config import bot, logger, db
from maxgram.keyboards import InlineKeyboard
from collections import Counter
from urllib.parse import urlparse

def get_safe_user_id(context):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ user_id"""
    try:
        return context.message['recipient']['chat_id']
    except:
        return "unknown"

def handle_rector_documents(context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–Ω–æ–ø–∫–∏ 'üìë –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏' - –∑–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10"""
    user_id = get_safe_user_id(context)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä
    context.reply_callback("üîÑ –ó–∞–ø—É—Å–∫–∞—é –ø–∞—Ä—Å–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.")
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∏ –ø–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        news_results, stats_message = run_parser_with_stats()
        
        if not news_results:
            message = "‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."
            keyboard = InlineKeyboard(
                [{"text": "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é", "callback": "back_to_menu"}]
            )
        else:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –ë–î
            news_list = get_recent_news_from_db(limit=10)
            
            if news_list:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∏ —Å–ø–∏—Å–∫–æ–º –Ω–æ–≤–æ—Å—Ç–µ–π
                message = "‚úÖ –ù–æ–≤–æ—Å—Ç–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\n\n"
                message += stats_message
                message += "\n\nüì∞ –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –Ω–æ–≤–æ—Å—Ç–µ–π –ù–ì–¢–£:\n\n"
                
                for i, news in enumerate(news_list, 1):
                    sentiment_emoji = {
                        "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π": "üìà",
                        "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π": "üòê", 
                        "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π": "üìâ"
                    }.get(news['sentiment'], 'üìÑ')
                    
                    # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title = news['title']
                    if len(title) > 80:
                        title = title[:77] + "..."
                    
                    # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –æ—Ç URL –∏ –æ–±—Ä–µ–∑–∞–µ–º
                    source = clean_source(news['source'])
                    if len(source) > 25:
                        source = source[:22] + "..."
                    
                    message += f"{i}. {sentiment_emoji} [{news['sentiment']}] {title}\n"
                    message += f"   üìÖ {news['date_text']} | üì∞ {source}\n\n"
                
                # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏-—Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å
                keyboard_rows = []
                for i, news in enumerate(news_list, 1):
                    # –û—á–∏—â–∞–µ–º —Å—Å—ã–ª–∫—É –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Google
                    clean_link = get_clean_news_link(news['link'])
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É —Å –ø–æ–ª–Ω–æ–π —Å—Å—ã–ª–∫–æ–π
                    keyboard_rows.append([
                        {"text": f"üîó –°—Å—ã–ª–∫–∞ –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å {i}", "url": clean_link}
                    ])
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É "–ù–∞–∑–∞–¥"
                keyboard_rows.append([
                    {"text": "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é", "callback": "back_to_menu"}
                ])
                
                keyboard = InlineKeyboard(*keyboard_rows)
            else:
                message = "üì≠ –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π.\n\n" + stats_message
                keyboard = InlineKeyboard(
                    [{"text": "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é", "callback": "back_to_menu"}]
                )
                
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏: {e}")
        message = "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π."
        keyboard = InlineKeyboard(
            [{"text": "üîô –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é", "callback": "back_to_menu"}]
        )
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ –∏ –∫–Ω–æ–ø–∫–∞–º–∏-—Å—Å—ã–ª–∫–∞–º–∏
    context.reply_callback(message, keyboard=keyboard)

def run_parser_with_stats():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–µ—Ä –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π"""
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    from rector.parser import search_google_news_alternative, save_news_to_db
    
    query = "–ù–ì–¢–£ –Ω–æ–≤–æ—Å—Ç–∏"
    
    print("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    results = search_google_news_alternative(query)
    
    if not results:
        print("–ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return [], ""
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(results)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    save_news_to_db(results)
    
    # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    sentiment_counts = Counter([news['sentiment'] for news in results])
    avg_score = sum(news['sentiment_score'] for news in results) / len(results)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    stats_message = "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏:\n"
    for sentiment in ["–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π", "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π", "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π"]:
        count = sentiment_counts.get(sentiment, 0)
        stats_message += f"  {sentiment}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π\n"
    stats_message += f"  –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {avg_score:.3f}"
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å (–∫–∞–∫ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ)
    print(f"\n{stats_message}")
    
    return results, stats_message

def get_recent_news_from_db(limit=10):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        with db.conn.cursor() as cur:
            cur.execute("""
                SELECT title, link, source, date_text, sentiment, sentiment_score
                FROM news 
                ORDER BY parsed_at DESC 
                LIMIT %s
            """, (limit,))
            
            news_list = []
            for row in cur.fetchall():
                news_list.append({
                    'title': row[0],
                    'link': row[1],
                    'source': row[2],
                    'date_text': row[3],
                    'sentiment': row[4],
                    'sentiment_score': float(row[5]) if row[5] else 0.0
                })
            
            return news_list
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –ë–î: {e}")
        return []

def get_clean_news_link(url):
    """–û—á–∏—â–∞–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Google"""
    try:
        # –û—á–∏—â–∞–µ–º URL –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Google
        if '/url?q=' in url:
            url = url.split('/url?q=')[1].split('&')[0]
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º URL-encoded —Å–∏–º–≤–æ–ª—ã
        from urllib.parse import unquote
        url = unquote(url)
        
        return url
            
    except:
        return url

def clean_source(source):
    """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –æ—Ç URL –∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ"""
    if not source:
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫"
    
    # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http, –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω
    if source.startswith('http'):
        return get_domain_from_url(source)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —á–∞—Å—Ç–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    source = source.replace('http://', '').replace('https://', '')
    
    # –£–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã RSS –∏ –¥—Ä—É–≥–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —á–∞—Å—Ç–∏
    if '?option=' in source:
        source = source.split('?')[0]
    
    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ —ç—Ç–æ –≤—Å–µ –µ—â–µ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ URL, –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω
    if '.' in source and ('/' in source or source.count('.') >= 2):
        try:
            parsed = urlparse('http://' + source if not source.startswith('http') else source)
            domain = parsed.netloc if parsed.netloc else parsed.path.split('/')[0]
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain
        except:
            pass
    
    return source

def get_domain_from_url(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ URL –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        # –û—á–∏—â–∞–µ–º URL –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Google
        if '/url?q=' in url:
            url = url.split('/url?q=')[1].split('&')[0]
        
        parsed = urlparse(url)
        domain = parsed.netloc
        
        # –£–±–∏—Ä–∞–µ–º www. –µ—Å–ª–∏ –µ—Å—Ç—å
        if domain.startswith('www.'):
            domain = domain[4:]
        
        return domain
    except:
        return "—Å—Å—ã–ª–∫–∞"